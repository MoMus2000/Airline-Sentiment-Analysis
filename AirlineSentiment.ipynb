{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AirlineSentiment.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMa4HKBqC+nvTXyTrPhmLwI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MoMus2000/Airline-Sentiment-Analysis/blob/master/AirlineSentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJdcK2kk3o-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding\n",
        "df = pd.read_csv('/content/Tweets.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prekRfhA4FaW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['airline_sentiment']=df['airline_sentiment'].map({'positive':1,'negative':0,'neutral':1})\n",
        "training_sentences = []\n",
        "training_labels = []\n",
        "for s in df['text'].to_numpy():\n",
        "    training_sentences.append(s)\n",
        "\n",
        "for l in df['airline_sentiment'].to_numpy():\n",
        "    training_labels.append(l)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Dh0E3HC4GGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "total_words = len(tokenizer.word_index)+1\n",
        "word_index = tokenizer.word_index\n",
        "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "max_sequence_len = max([len(x) for x in training_sentences])\n",
        "padded = pad_sequences(sequences,maxlen=max_sequence_len-1, truncating = 'post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ArpfMtX4SWl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 300, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(64)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEmq9toz4XeD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss = 'binary_crossentropy',optimizer = tf.keras.optimizers.Adam(),metrics = ['accuracy'])\n",
        "training_labels_final = np.array(training_labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MPqkFs34ZlL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ca76f4d3-2dd9-41fb-92cc-c2cc15b24627"
      },
      "source": [
        "model.fit(padded,training_labels_final,epochs=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "458/458 [==============================] - 54s 117ms/step - loss: 0.3255 - accuracy: 0.8682\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbafc4ca080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p81aB12M7GGo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "579af9ea-e7f0-4690-cbde-be27511ae656"
      },
      "source": [
        "tokenize = Tokenizer()\n",
        "Test = [\"@Emirates i shit hate fuck ugly mean your flights\"]\n",
        "tokenize.fit_on_texts(Test)\n",
        "sequence = tokenizer.texts_to_sequences(Test)\n",
        "print(sequence)\n",
        "padde = pad_sequences(sequence,maxlen=max_sequence_len-1, truncating = 'post')\n",
        "print(model.predict(padde))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6809, 3, 848, 770, 1212, 591, 21, 64]]\n",
            "[[0.6216275]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}